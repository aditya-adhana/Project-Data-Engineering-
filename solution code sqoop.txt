
-------sqoop data import from mysql--------------------------------------

sqoop import-all-tables  --connect jdbc:mysql://ip-10-1-1-204.ap-south-1.compute.internal:3306/anabig114225 --username anabig114225 --password Bigdata123 --compression-codec=snappy --as-avrodatafile --warehouse-dir=/user/anabig114225/projectdata --m 1 --driver com.mysql.jdbc.Driver

hdfs dfs -mkdir projectschema
hdfs dfs -copyFromLocal ~/*.avsc projectschema


---------------------------------- hive table creation-------------------------
create database project_de
use project_de


CREATE EXTERNAL TABLE employees STORED AS AVRO 
LOCATION '/user/anabig114225/projectdata/employees' 
TBLPROPERTIES ('avro.schema.url'='/user/anabig114225/projectschema/employees.avsc');

CREATE EXTERNAL TABLE titles STORED AS AVRO 
LOCATION '/user/anabig114225/projectdata/titles' 
TBLPROPERTIES ('avro.schema.url'='/user/anabig114225/projectschema/titles.avsc');

CREATE EXTERNAL TABLE salaries STORED AS AVRO 
LOCATION '/user/anabig114225/projectdata/salaries' 
TBLPROPERTIES ('avro.schema.url'='/user/anabig114225/projectschema/salaries.avsc');

CREATE EXTERNAL TABLE departments STORED AS AVRO 
LOCATION '/user/anabig114225/projectdata/departments' 
TBLPROPERTIES ('avro.schema.url'='/user/anabig114225/projectschema/departments.avsc');

CREATE EXTERNAL TABLE department_manager STORED AS AVRO 
LOCATION '/user/anabig114225/projectdata/department_manager' 
TBLPROPERTIES ('avro.schema.url'='/user/anabig114225/projectschema/department_manager.avsc');

CREATE EXTERNAL TABLE department_employees STORED AS AVRO 
LOCATION '/user/anabig114225/projectdata/department_employees' 
TBLPROPERTIES ('avro.schema.url'='/user/anabig114225/projectschema/department_employees.avsc');


---------------------------pyspark importing data from hive ------------------------------

from pyspark.sql import SparkSession

spark=(SparkSession.builder.appName("Capstone Project")\
      .config("hive.metastore.uris","thrift://ip-10-1-2-24.ap-south-1.compute.internal:8889")\
      .enableHiveSupport().getOrCreate())
	  
# importing tables from hive 

employees=spark.sql("select * from project_de.employees")
titles=spark.sql("select * from project_de.titles")
salaries=spark.sql("select * from project_de.salaries")
departments=spark.sql("select * from project_de.departments")
department_manager=spark.sql("select * from project_de.department_manager")
department_employees=spark.sql("select * from project_de.department_employees")