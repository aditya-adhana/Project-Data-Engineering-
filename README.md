# Project-Data-Engineering-
Major task is to work on data engineering project for one of the big corporationâ€™s employees data from the 1980s and 1995s. All the database of employees 
from that period are provided six CSV files.
Design data model with all the tables to hold data, import the CSVs into a SQL database, transfer SQL database to HDFS/Hive, 
and perform analysis using Hive/Impala/Spark/SparkML using the data and create data and ML pipelines.
Required to create end to end data pipeline and analyzing the data.

The data is contained in the 6 csv files:

1. titles.csv -> This file contains the different job titles of the employees.
2. employees.csv -> Contains all data related to each employee, such as employee id, name, age,sex, date of hiring, etc.
3. salaries.csv -> contains salary of each employee.
4. departments.csv -> enlists the various departments in the company.
5. dept_manager.csv -> indicates which employee manages which department.
6. dept_emp.csv -> indicates wich department each employee belongs to.

Technology Stack:
Worked on below technologies to complete this project.
Mysql, linux, sqoop, hdfs, hive, Impala, SparkSQL, SparkML

steps performed by each technology 
- MySQL (to create database)
- Linux Commands
- Sqoop (Transfer data from MySQL Server to HDFS/Hive)
- HDFS (to store the data)
- Hive (to create database)
- Impala (to perform the EDA)
- SparkSQL (to perform the EDA)
- SparkML (to perform model building

All the codes are given accordingly as per the steps and finally a Project Documentation has been prepared well. 
